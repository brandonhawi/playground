{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flagrant Fouls Data Collection\n",
    "\n",
    "Extract flagrant foul data from NBA API for seasons 2020-21 through 2024-25.\n",
    "\n",
    "- Loads existing CSV to avoid duplicate game IDs\n",
    "- Fetches new games from API\n",
    "- Saves to CSV immediately after each successful API call\n",
    "- Stops on first read timeout (1 hour cooldown needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from nba_api.stats.endpoints.leaguegamefinder import LeagueGameFinder\n",
    "from nba_api.stats.endpoints.playbyplayv3 import PlayByPlayV3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "csv_file = Path('nba_flagrant_fouls.csv')\n",
    "\n",
    "# Load existing data if it exists\n",
    "if csv_file.exists():\n",
    "    existing_df = pd.read_csv(csv_file)\n",
    "    existing_game_ids = set(existing_df['game_id'].unique())\n",
    "    print(f\"Loaded existing CSV with {len(existing_df)} games\")\n",
    "    print(f\"Unique game IDs to skip: {len(existing_game_ids)}\")\n",
    "else:\n",
    "    existing_df = pd.DataFrame()\n",
    "    existing_game_ids = set()\n",
    "    print(\"No existing CSV found. Starting fresh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def extract_game_data(game_id):\n",
    "    \"\"\"\n",
    "    Extract flagrant fouls and game outcome from a single game.\n",
    "    \n",
    "    Args:\n",
    "        game_id: NBA game ID\n",
    "    \n",
    "    Returns:\n",
    "        dict: Game data or None if error occurs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = PlayByPlayV3(game_id=game_id)\n",
    "        pbp = response.play_by_play.get_data_frame()\n",
    "        \n",
    "        # Extract flagrants by team\n",
    "        flagrants = pbp[pbp['subType'].isin(['Flagrant Type 1', 'Flagrant Type 2'])]\n",
    "        \n",
    "        home_flagrants = len(flagrants[flagrants['location'] == 'h'])\n",
    "        away_flagrants = len(flagrants[flagrants['location'] == 'v'])\n",
    "        \n",
    "        # Get final score (from last row)\n",
    "        final_row = pbp.iloc[-1]\n",
    "        home_score = final_row['scoreHome']\n",
    "        away_score = final_row['scoreAway']\n",
    "        \n",
    "        # Get team IDs (from first non-empty row)\n",
    "        team_rows = pbp[pbp['teamId'] != 0]\n",
    "        home_team = team_rows[team_rows['location'] == 'h']['teamId'].iloc[0]\n",
    "        away_team = team_rows[team_rows['location'] == 'v']['teamId'].iloc[0]\n",
    "        \n",
    "        return {\n",
    "            'game_id': game_id,\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'home_flagrants': home_flagrants,\n",
    "            'away_flagrants': away_flagrants,\n",
    "            'home_score': home_score,\n",
    "            'away_score': away_score\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch Games from NBA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define seasons to extract\n",
    "seasons = ['2020-21', '2021-22', '2022-23', '2023-24', '2024-25']\n",
    "\n",
    "all_game_ids = []\n",
    "\n",
    "print(f\"Fetching game IDs from {len(seasons)} seasons...\")\n",
    "for season in seasons:\n",
    "    try:\n",
    "        gamefinder = LeagueGameFinder(season_nullable=season)\n",
    "        games_df = gamefinder.get_data_frames()[0]\n",
    "        game_ids = games_df['GAME_ID'].unique()\n",
    "        all_game_ids.extend(game_ids)\n",
    "        print(f\"  {season}: {len(game_ids)} games\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {season}: ERROR - {type(e).__name__}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTotal unique games: {len(set(all_game_ids))}\")\n",
    "\n",
    "# Filter out games already in CSV\n",
    "new_game_ids = [gid for gid in all_game_ids if gid not in existing_game_ids]\n",
    "print(f\"New games to extract: {len(new_game_ids)}\")\n",
    "print(f\"Games to skip (already in CSV): {len(all_game_ids) - len(new_game_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Flagrant Foul Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(f\"\\nStarting data extraction for {len(new_game_ids)} new games...\")\n",
    "print(f\"(1 second throttle between API calls)\\n\")\n",
    "\n",
    "successful_count = 0\n",
    "skipped_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "try:\n",
    "    for i, game_id in enumerate(new_game_ids):\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(f\"Progress: {i}/{len(new_game_ids)} | Saved: {successful_count} | Errors: {failed_count}\")\n",
    "        \n",
    "        game_data, error = extract_game_data(game_id)\n",
    "        \n",
    "        if game_data:\n",
    "            # Convert to DataFrame and save immediately\n",
    "            game_df = pd.DataFrame([game_data])\n",
    "            \n",
    "            # Append to CSV\n",
    "            if csv_file.exists():\n",
    "                game_df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "            else:\n",
    "                game_df.to_csv(csv_file, mode='w', header=True, index=False)\n",
    "            \n",
    "            successful_count += 1\n",
    "        else:\n",
    "            # Check if it's a read timeout\n",
    "            if 'ReadTimeout' in str(type(error).__name__) or 'timeout' in str(error).lower():\n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(f\"READ TIMEOUT DETECTED - IP likely rate limited\")\n",
    "                print(f\"{'='*70}\")\n",
    "                \n",
    "                # Calculate 1 hour from now\n",
    "                retry_time = datetime.now() + timedelta(hours=1)\n",
    "                print(f\"\\nPlease wait until: {retry_time.strftime('%Y-%m-%d %H:%M:%S')} (local time)\")\n",
    "                print(f\"This is approximately 1 hour from now.\")\n",
    "                print(f\"\\nProgress so far:\")\n",
    "                print(f\"  Games extracted: {successful_count}\")\n",
    "                print(f\"  Games processed: {i + 1}/{len(new_game_ids)}\")\n",
    "                print(f\"\\nRun this notebook again in 1 hour to continue extraction.\")\n",
    "                break\n",
    "            else:\n",
    "                failed_count += 1\n",
    "        \n",
    "        # Throttle to avoid rate limiting\n",
    "        time.sleep(1.0)\n",
    "\nexcept KeyboardInterrupt:\n",
    "    print(f\"\\n\\nInterrupted by user\")\n",
    "\nprint(f\"\\n{'='*70}\")\nprint(f\"EXTRACTION COMPLETE\")\nprint(f\"{'='*70}\")\nprint(f\"Successfully saved: {successful_count} games\")\nprint(f\"Errors encountered: {failed_count} games\")\nprint(f\"Total processed: {successful_count + failed_count}/{len(new_game_ids)}\")\nprint(f\"Data saved to: {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load and display summary\n",
    "final_df = pd.read_csv(csv_file)\n",
    "\n",
    "print(f\"\\nFinal CSV Summary:\")\n",
    "print(f\"Total games: {len(final_df)}\")\n",
    "print(f\"Unique games: {final_df['game_id'].nunique()}\")\nprint(f\"\\nGames per season (inferred from game_id):\")\n",
    "final_df['season'] = final_df['game_id'].str[3:7]  # Extract year from game_id\n",
    "print(final_df.groupby('season').size().sort_index())\n",
    "print(f\"\\nData shape: {final_df.shape}\")\n",
    "print(f\"Columns: {final_df.columns.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
