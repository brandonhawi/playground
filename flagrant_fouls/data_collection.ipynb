{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flagrant Fouls Data Collection\n",
    "\n",
    "Extract flagrant foul data from NBA API for seasons 2020-21 through 2024-25.\n",
    "\n",
    "- Loads existing CSV to avoid duplicate game IDs\n",
    "- Fetches new games from API\n",
    "- Saves to CSV immediately after each successful API call\n",
    "- Stops on first read timeout (1 hour cooldown needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from nba_api.stats.endpoints.leaguegamefinder import LeagueGameFinder\n",
    "from nba_api.stats.endpoints.playbyplayv3 import PlayByPlayV3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing CSV with 2024 games\n",
      "Unique game IDs to skip: 2024\n",
      "No skipped games file found.\n"
     ]
    }
   ],
   "source": [
    "csv_file = Path('nba_flagrant_fouls.csv')\n",
    "skipped_file = Path('nba_skipped_games.csv')\n",
    "\n",
    "# Load existing data if it exists\n",
    "if csv_file.exists():\n",
    "    existing_df = pd.read_csv(csv_file, dtype={'game_id': str})\n",
    "    # Ensure game_id is string and pad to 10 digits\n",
    "    existing_df['game_id'] = existing_df['game_id'].astype(str).str.zfill(10)\n",
    "    existing_game_ids = set(existing_df['game_id'].unique())\n",
    "    print(f\"Loaded existing CSV with {len(existing_df)} games\")\n",
    "    print(f\"Unique game IDs to skip: {len(existing_game_ids)}\")\n",
    "else:\n",
    "    existing_df = pd.DataFrame()\n",
    "    existing_game_ids = set()\n",
    "    print(\"No existing CSV found. Starting fresh.\")\n",
    "\n",
    "# Load skipped games if exists\n",
    "if skipped_file.exists():\n",
    "    skipped_df = pd.read_csv(skipped_file, dtype={'game_id': str})\n",
    "    skipped_df['game_id'] = skipped_df['game_id'].astype(str).str.zfill(10)\n",
    "    existing_game_ids.update(skipped_df['game_id'].unique())\n",
    "    print(f\"Loaded {len(skipped_df)} previously skipped games\")\n",
    "else:\n",
    "    skipped_df = pd.DataFrame()\n",
    "    print(\"No skipped games file found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_game_data(game_id):\n",
    "    \"\"\"\n",
    "    Extract flagrant fouls and game outcome from a single game.\n",
    "\n",
    "    Args:\n",
    "        game_id: NBA game ID\n",
    "\n",
    "    Returns:\n",
    "        tuple: (game_data dict, error) - one will be None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = PlayByPlayV3(game_id=game_id)\n",
    "        pbp = response.play_by_play.get_data_frame()\n",
    "\n",
    "        # Check if play-by-play data is empty\n",
    "        if pbp.empty:\n",
    "            return None, ValueError(\"No play-by-play data available for this game\")\n",
    "\n",
    "        # Extract flagrants by team\n",
    "        flagrants = pbp[pbp['subType'].isin(['Flagrant Type 1', 'Flagrant Type 2'])]\n",
    "\n",
    "        home_flagrants = len(flagrants[flagrants['location'] == 'h'])\n",
    "        away_flagrants = len(flagrants[flagrants['location'] == 'v'])\n",
    "\n",
    "        # Get final score (from last row)\n",
    "        final_row = pbp.iloc[-1]\n",
    "        home_score = final_row['scoreHome']\n",
    "        away_score = final_row['scoreAway']\n",
    "\n",
    "        # Get team IDs - safely extract with validation\n",
    "        team_rows = pbp[(pbp['teamId'] != 0) & (pbp['location'].isin(['h', 'v']))]\n",
    "\n",
    "        if len(team_rows) == 0:\n",
    "            return None, ValueError(\"No team data found in play-by-play\")\n",
    "\n",
    "        home_candidates = team_rows[team_rows['location'] == 'h']['teamId']\n",
    "        away_candidates = team_rows[team_rows['location'] == 'v']['teamId']\n",
    "\n",
    "        if len(home_candidates) == 0 or len(away_candidates) == 0:\n",
    "            return None, ValueError(\"Missing home or away team data\")\n",
    "\n",
    "        home_team = home_candidates.iloc[0]\n",
    "        away_team = away_candidates.iloc[0]\n",
    "\n",
    "        game_data = {\n",
    "            'game_id': game_id,\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'home_flagrants': home_flagrants,\n",
    "            'away_flagrants': away_flagrants,\n",
    "            'home_score': home_score,\n",
    "            'away_score': away_score\n",
    "        }\n",
    "        return game_data, None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch Games from NBA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching game IDs from 5 seasons...\n",
      "  2020-21: 1221 games\n",
      "  2021-22: 1394 games\n",
      "  2022-23: 1395 games\n",
      "  2023-24: 1397 games\n",
      "  2024-25: 1401 games\n",
      "\n",
      "Total unique games: 6808\n",
      "New games to extract: 4784\n",
      "Games to skip (already processed): 2024\n"
     ]
    }
   ],
   "source": [
    "# Define seasons to extract\n",
    "seasons = ['2020-21', '2021-22', '2022-23', '2023-24', '2024-25']\n",
    "\n",
    "all_game_ids = []\n",
    "\n",
    "print(f\"Fetching game IDs from {len(seasons)} seasons...\")\n",
    "for season in seasons:\n",
    "    try:\n",
    "        gamefinder = LeagueGameFinder(season_nullable=season)\n",
    "        games_df = gamefinder.get_data_frames()[0]\n",
    "        game_ids = games_df['GAME_ID'].unique()\n",
    "        all_game_ids.extend(game_ids)\n",
    "        print(f\"  {season}: {len(game_ids)} games\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {season}: ERROR - {type(e).__name__}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTotal unique games: {len(set(all_game_ids))}\")\n",
    "\n",
    "# Keep game IDs as strings (DO NOT convert to integers - this strips leading zeros!)\n",
    "# API requires 10-digit strings like '0022000605'\n",
    "all_game_ids_str = [str(gid) for gid in all_game_ids]\n",
    "\n",
    "# Filter out games already in CSV or skipped\n",
    "new_game_ids = [gid for gid in all_game_ids_str if gid not in existing_game_ids]\n",
    "print(f\"New games to extract: {len(new_game_ids)}\")\n",
    "print(f\"Games to skip (already processed): {len(all_game_ids_str) - len(new_game_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Flagrant Foul Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data extraction for 4784 new games...\n",
      "Progress: 100/4784 | Saved: 100 | Skipped: 0 | Errors: 0\n",
      "Progress: 200/4784 | Saved: 200 | Skipped: 0 | Errors: 0\n",
      "\n",
      "======================================================================\n",
      "READ TIMEOUT DETECTED - IP likely rate limited\n",
      "======================================================================\n",
      "\n",
      "Please wait until: 2025-11-30 09:02:26 (local time)\n",
      "This is approximately 1 hour from now.\n",
      "\n",
      "Progress so far:\n",
      "  Games extracted: 258\n",
      "  Games processed: 260/4784\n",
      "\n",
      "Run this notebook again in 1 hour to continue extraction.\n",
      "\n",
      "======================================================================\n",
      "EXTRACTION COMPLETE\n",
      "======================================================================\n",
      "Successfully saved: 258 games\n",
      "Skipped (no data): 1 games\n",
      "Errors encountered: 0 games\n",
      "Total processed: 259/4784\n",
      "Data saved to: nba_flagrant_fouls.csv\n",
      "Skipped games logged to: nba_skipped_games.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nStarting data extraction for {len(new_game_ids)} new games...\")\n",
    "\n",
    "successful_count = 0\n",
    "failed_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "try:\n",
    "    for i, game_id in enumerate(new_game_ids):\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(f\"Progress: {i}/{len(new_game_ids)} | Saved: {successful_count} | Skipped: {skipped_count} | Errors: {failed_count}\")\n",
    "\n",
    "        game_data, error = extract_game_data(game_id)\n",
    "\n",
    "        if game_data:\n",
    "            # Ensure game_id is stored as string with leading zeros\n",
    "            game_data['game_id'] = str(game_data['game_id']).zfill(10)\n",
    "            \n",
    "            # Convert to DataFrame and save immediately\n",
    "            game_df = pd.DataFrame([game_data])\n",
    "\n",
    "            # Append to CSV\n",
    "            if csv_file.exists():\n",
    "                game_df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "            else:\n",
    "                game_df.to_csv(csv_file, mode='w', header=True, index=False)\n",
    "\n",
    "            successful_count += 1\n",
    "        else:\n",
    "            # Check if it's a read timeout\n",
    "            if 'ReadTimeout' in str(type(error).__name__) or 'timeout' in str(error).lower():\n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(f\"READ TIMEOUT DETECTED - IP likely rate limited\")\n",
    "                print(f\"{'='*70}\")\n",
    "\n",
    "                # Calculate 1 hour from now\n",
    "                retry_time = datetime.now() + timedelta(hours=1)\n",
    "                print(f\"\\nPlease wait until: {retry_time.strftime('%Y-%m-%d %H:%M:%S')} (local time)\")\n",
    "                print(f\"This is approximately 1 hour from now.\")\n",
    "                print(f\"\\nProgress so far:\")\n",
    "                print(f\"  Games extracted: {successful_count}\")\n",
    "                print(f\"  Games processed: {i + 1}/{len(new_game_ids)}\")\n",
    "                print(f\"\\nRun this notebook again in 1 hour to continue extraction.\")\n",
    "                break\n",
    "            elif isinstance(error, ValueError):\n",
    "                # Track games with no data in separate file\n",
    "                skipped_game_df = pd.DataFrame([{\n",
    "                    'game_id': str(game_id).zfill(10),  # Ensure string format\n",
    "                    'reason': str(error),\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }])\n",
    "                \n",
    "                if skipped_file.exists():\n",
    "                    skipped_game_df.to_csv(skipped_file, mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    skipped_game_df.to_csv(skipped_file, mode='w', header=True, index=False)\n",
    "                \n",
    "                skipped_count += 1\n",
    "            else:\n",
    "                print(f\"Error extracting game {game_id}: {type(error).__name__} - {error}\")\n",
    "                failed_count += 1\n",
    "\n",
    "        # Throttle to avoid rate limiting\n",
    "        time.sleep(0.600)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n\\nInterrupted by user\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"EXTRACTION COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Successfully saved: {successful_count} games\")\n",
    "print(f\"Skipped (no data): {skipped_count} games\")\n",
    "print(f\"Errors encountered: {failed_count} games\")\n",
    "print(f\"Total processed: {successful_count + skipped_count + failed_count}/{len(new_game_ids)}\")\n",
    "print(f\"Data saved to: {csv_file}\")\n",
    "if skipped_count > 0:\n",
    "    print(f\"Skipped games logged to: {skipped_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final CSV Summary:\n",
      "Total games: 2282\n",
      "Unique games: 2282\n",
      "\n",
      "Sample game IDs (first 5):\n",
      "  0042300405\n",
      "  0042300404\n",
      "  0042300403\n",
      "  0042300402\n",
      "  0042300401\n",
      "\n",
      "Games per season (inferred from game_id):\n",
      "season\n",
      "0120      49\n",
      "0220    1080\n",
      "0221     364\n",
      "0223     507\n",
      "0320       1\n",
      "0321       4\n",
      "0323       5\n",
      "0420      85\n",
      "0421      87\n",
      "0423      82\n",
      "0520       6\n",
      "0521       6\n",
      "0523       6\n",
      "dtype: int64\n",
      "\n",
      "Data shape: (2282, 8)\n",
      "Columns: ['game_id', 'home_team', 'away_team', 'home_flagrants', 'away_flagrants', 'home_score', 'away_score', 'season']\n",
      "Game ID format: object (10-digit strings with leading zeros)\n"
     ]
    }
   ],
   "source": [
    "# Load and display summary (with correct dtype to preserve string format)\n",
    "final_df = pd.read_csv(csv_file, dtype={'game_id': str})\n",
    "\n",
    "print(f\"\\nFinal CSV Summary:\")\n",
    "print(f\"Total games: {len(final_df)}\")\n",
    "print(f\"Unique games: {final_df['game_id'].nunique()}\")\n",
    "print(f\"\\nSample game IDs (first 5):\")\n",
    "for gid in final_df['game_id'].head():\n",
    "    print(f\"  {gid}\")\n",
    "\n",
    "print(f\"\\nGames per season (inferred from game_id):\")\n",
    "final_df['season'] = final_df['game_id'].str[1:5]  # Extract season code from positions 1-4\n",
    "print(final_df.groupby('season').size().sort_index())\n",
    "\n",
    "print(f\"\\nData shape: {final_df.shape}\")\n",
    "print(f\"Columns: {final_df.columns.tolist()}\")\n",
    "print(f\"Game ID format: {final_df['game_id'].dtype} (10-digit strings with leading zeros)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
