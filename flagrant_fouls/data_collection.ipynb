{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Flagrant Fouls Data Collection\n\nExtract flagrant foul data and box score statistics from NBA API for seasons 2020-21 through 2024-25.\n\n**Data collected per game:**\n- Flagrant fouls (home/away)\n- Final scores (home/away)\n- Rebounds (home/away)\n- Assists (home/away)\n- Turnovers (home/away)\n- Free throws made/attempted (home/away)\n- Inactive players count (home/away)\n\n**Process:**\n- Loads existing CSV to avoid duplicate game IDs\n- Fetches new games from API\n- Saves to CSV immediately after each successful API call\n- Stops on first read timeout (1 hour cooldown needed)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport time\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom nba_api.stats.endpoints.leaguegamefinder import LeagueGameFinder\nfrom nba_api.stats.endpoints.playbyplayv3 import PlayByPlayV3\nfrom nba_api.stats.endpoints.boxscoretraditionalv3 import BoxScoreTraditionalV3\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing CSV with 600 games\n",
      "Unique game IDs to skip: 600\n"
     ]
    }
   ],
   "source": [
    "csv_file = Path('nba_flagrant_fouls.csv')\n",
    "\n",
    "# Load existing data if it exists\n",
    "if csv_file.exists():\n",
    "    existing_df = pd.read_csv(csv_file)\n",
    "    existing_game_ids = set(existing_df['game_id'].unique())\n",
    "    print(f\"Loaded existing CSV with {len(existing_df)} games\")\n",
    "    print(f\"Unique game IDs to skip: {len(existing_game_ids)}\")\n",
    "else:\n",
    "    existing_df = pd.DataFrame()\n",
    "    existing_game_ids = set()\n",
    "    print(\"No existing CSV found. Starting fresh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_game_data(game_id):\n    \"\"\"\n    Extract flagrant fouls, game outcome, and box score statistics from a single game.\n    \n    Args:\n        game_id: NBA game ID\n    \n    Returns:\n        tuple: (game_data dict, error) - one will be None\n    \"\"\"\n    try:\n        # Get play-by-play for flagrant fouls\n        pbp_response = PlayByPlayV3(game_id=game_id)\n        pbp = pbp_response.play_by_play.get_data_frame()\n        \n        # Extract flagrants by team\n        flagrants = pbp[pbp['subType'].isin(['Flagrant Type 1', 'Flagrant Type 2'])]\n        \n        home_flagrants = len(flagrants[flagrants['location'] == 'h'])\n        away_flagrants = len(flagrants[flagrants['location'] == 'v'])\n        \n        # Get final score (from last row)\n        final_row = pbp.iloc[-1]\n        home_score = final_row['scoreHome']\n        away_score = final_row['scoreAway']\n        \n        # Get team IDs (from first non-empty row)\n        team_rows = pbp[pbp['teamId'] != 0]\n        home_team = team_rows[team_rows['location'] == 'h']['teamId'].iloc[0]\n        away_team = team_rows[team_rows['location'] == 'v']['teamId'].iloc[0]\n        \n        # Get box score statistics\n        box_response = BoxScoreTraditionalV3(game_id=game_id)\n        box_stats = box_response.box_score_player_stats.get_data_frame()\n        \n        # Aggregate team-level statistics\n        team_stats = box_stats.groupby('teamId').agg({\n            'reb': 'sum',      # Total rebounds\n            'ast': 'sum',      # Assists\n            'tov': 'sum',      # Turnovers\n            'ftm': 'sum',      # Free throws made\n            'fta': 'sum'       # Free throws attempted\n        }).to_dict('index')\n        \n        # Extract stats for each team\n        home_stats = team_stats.get(home_team, {})\n        away_stats = team_stats.get(away_team, {})\n        \n        # Count inactive players (proxy for injuries)\n        # Players with 0 minutes played and DNP status\n        home_inactive = len(box_stats[(box_stats['teamId'] == home_team) & (box_stats['min'] == 0)])\n        away_inactive = len(box_stats[(box_stats['teamId'] == away_team) & (box_stats['min'] == 0)])\n        \n        game_data = {\n            'game_id': game_id,\n            'home_team': home_team,\n            'away_team': away_team,\n            'home_flagrants': home_flagrants,\n            'away_flagrants': away_flagrants,\n            'home_score': home_score,\n            'away_score': away_score,\n            'home_rebounds': home_stats.get('reb', 0),\n            'away_rebounds': away_stats.get('reb', 0),\n            'home_assists': home_stats.get('ast', 0),\n            'away_assists': away_stats.get('ast', 0),\n            'home_turnovers': home_stats.get('tov', 0),\n            'away_turnovers': away_stats.get('tov', 0),\n            'home_ftm': home_stats.get('ftm', 0),\n            'away_ftm': away_stats.get('ftm', 0),\n            'home_fta': home_stats.get('fta', 0),\n            'away_fta': away_stats.get('fta', 0),\n            'home_inactive_players': home_inactive,\n            'away_inactive_players': away_inactive\n        }\n        return game_data, None\n    \n    except Exception as e:\n        return None, e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch Games from NBA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching game IDs from 5 seasons...\n",
      "  2020-21: 1221 games\n",
      "  2021-22: 1394 games\n",
      "  2022-23: 1395 games\n",
      "  2023-24: 1397 games\n",
      "  2024-25: 1401 games\n",
      "\n",
      "Total unique games: 6808\n",
      "New games to extract: 6808\n",
      "Games to skip (already in CSV): 0\n"
     ]
    }
   ],
   "source": [
    "# Define seasons to extract\n",
    "seasons = ['2020-21', '2021-22', '2022-23', '2023-24', '2024-25']\n",
    "\n",
    "all_game_ids = []\n",
    "\n",
    "print(f\"Fetching game IDs from {len(seasons)} seasons...\")\n",
    "for season in seasons:\n",
    "    try:\n",
    "        gamefinder = LeagueGameFinder(season_nullable=season)\n",
    "        games_df = gamefinder.get_data_frames()[0]\n",
    "        game_ids = games_df['GAME_ID'].unique()\n",
    "        all_game_ids.extend(game_ids)\n",
    "        print(f\"  {season}: {len(game_ids)} games\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {season}: ERROR - {type(e).__name__}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTotal unique games: {len(set(all_game_ids))}\")\n",
    "\n",
    "# Filter out games already in CSV\n",
    "new_game_ids = [gid for gid in all_game_ids if gid not in existing_game_ids]\n",
    "print(f\"New games to extract: {len(new_game_ids)}\")\n",
    "print(f\"Games to skip (already in CSV): {len(all_game_ids) - len(new_game_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Flagrant Foul Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data extraction for 6808 new games...\n",
      "(1 second throttle between API calls)\n",
      "\n",
      "Progress: 100/6808 | Saved: 100 | Errors: 0\n",
      "Progress: 200/6808 | Saved: 200 | Errors: 0\n",
      "Progress: 300/6808 | Saved: 300 | Errors: 0\n",
      "Progress: 400/6808 | Saved: 400 | Errors: 0\n",
      "Progress: 500/6808 | Saved: 500 | Errors: 0\n",
      "\n",
      "======================================================================\n",
      "READ TIMEOUT DETECTED - IP likely rate limited\n",
      "======================================================================\n",
      "\n",
      "Please wait until: 2025-11-29 12:23:01 (local time)\n",
      "This is approximately 1 hour from now.\n",
      "\n",
      "Progress so far:\n",
      "  Games extracted: 597\n",
      "  Games processed: 598/6808\n",
      "\n",
      "Run this notebook again in 1 hour to continue extraction.\n",
      "\n",
      "======================================================================\n",
      "EXTRACTION COMPLETE\n",
      "======================================================================\n",
      "Successfully saved: 597 games\n",
      "Errors encountered: 0 games\n",
      "Total processed: 597/6808\n",
      "Data saved to: nba_flagrant_fouls.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nStarting data extraction for {len(new_game_ids)} new games...\")\n",
    "print(f\"(1 second throttle between API calls)\\n\")\n",
    "\n",
    "successful_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "try:\n",
    "    for i, game_id in enumerate(new_game_ids):\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(f\"Progress: {i}/{len(new_game_ids)} | Saved: {successful_count} | Errors: {failed_count}\")\n",
    "        \n",
    "        game_data, error = extract_game_data(game_id)\n",
    "        \n",
    "        if game_data:\n",
    "            # Convert to DataFrame and save immediately\n",
    "            game_df = pd.DataFrame([game_data])\n",
    "            \n",
    "            # Append to CSV\n",
    "            if csv_file.exists():\n",
    "                game_df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "            else:\n",
    "                game_df.to_csv(csv_file, mode='w', header=True, index=False)\n",
    "            \n",
    "            successful_count += 1\n",
    "        else:\n",
    "            # Check if it's a read timeout\n",
    "            if 'ReadTimeout' in str(type(error).__name__) or 'timeout' in str(error).lower():\n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(f\"READ TIMEOUT DETECTED - IP likely rate limited\")\n",
    "                print(f\"{'='*70}\")\n",
    "                \n",
    "                # Calculate 1 hour from now\n",
    "                retry_time = datetime.now() + timedelta(hours=1)\n",
    "                print(f\"\\nPlease wait until: {retry_time.strftime('%Y-%m-%d %H:%M:%S')} (local time)\")\n",
    "                print(f\"This is approximately 1 hour from now.\")\n",
    "                print(f\"\\nProgress so far:\")\n",
    "                print(f\"  Games extracted: {successful_count}\")\n",
    "                print(f\"  Games processed: {i + 1}/{len(new_game_ids)}\")\n",
    "                print(f\"\\nRun this notebook again in 1 hour to continue extraction.\")\n",
    "                break\n",
    "            else:\n",
    "                failed_count += 1\n",
    "        \n",
    "        # Throttle to avoid rate limiting\n",
    "        time.sleep(1.0)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n\\nInterrupted by user\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"EXTRACTION COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Successfully saved: {successful_count} games\")\n",
    "print(f\"Errors encountered: {failed_count} games\")\n",
    "print(f\"Total processed: {successful_count + failed_count}/{len(new_game_ids)}\")\n",
    "print(f\"Data saved to: {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final CSV Summary:\n",
      "Total games: 1197\n",
      "Unique games: 1197\n",
      "\n",
      "Games per season (inferred from game_id):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique games: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGames per season (inferred from game_id):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgame_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m[\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m7\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39msort_index())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/playground/.venv/lib/python3.10/site-packages/pandas/core/generic.py:6321\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6315\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6316\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6317\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6318\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6319\u001b[0m ):\n\u001b[1;32m   6320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/playground/.venv/lib/python3.10/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/Projects/playground/.venv/lib/python3.10/site-packages/pandas/core/strings/accessor.py:194\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m~/Projects/playground/.venv/lib/python3.10/site-packages/pandas/core/strings/accessor.py:248\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    245\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# Load and display summary\n",
    "final_df = pd.read_csv(csv_file)\n",
    "\n",
    "print(f\"\\nFinal CSV Summary:\")\n",
    "print(f\"Total games: {len(final_df)}\")\n",
    "print(f\"Unique games: {final_df['game_id'].nunique()}\")\n",
    "print(f\"\\nGames per season (inferred from game_id):\")\n",
    "final_df['season'] = final_df['game_id'].str[3:7]\n",
    "print(final_df.groupby('season').size().sort_index())\n",
    "print(f\"\\nData shape: {final_df.shape}\")\n",
    "print(f\"Columns: {final_df.columns.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}